# Mini Warehouse ML â€“ End-to-End Data Engineering Pipeline

Kompleksowy projekt Data Engineering + ML z peÅ‚nym pipelineâ€™em ETL dziaÅ‚ajÄ…cym w stylu produkcyjnym:

- **Apache Airflow** â€“ orkiestracja
- **MinIO (S3)** â€“ storage plikÃ³w
- **PostgreSQL** â€“ hurtownia danych w warstwach `bronze / silver / gold / ml`
- **Python + Pandas + scikit-learn + XGBoost** â€“ transformacje i modele
- **SQL** â€“ walidacja, czyszczenie, feature engineering
- **Docker Compose** â€“ peÅ‚na infrastruktura lokalna
- **Artifacts** â€“ zapisywanie modeli, metryk, SHAP i predykcji

CaÅ‚oÅ›Ä‡ jest zaprojektowana jako **portfolio-quality project**.

---

## Spis treÅ›ci

1. [Architektura](#architektura)
2. [Struktura repozytorium](#struktura-repozytorium)
3. [Warstwy hurtowni danych](#warstwy-hurtowni-danych)
4. [ERD â€“ zaleÅ¼noÅ›ci miÄ™dzy tabelami (Mermaid)](#erd--zaleÅ¼noÅ›ci-miÄ™dzy-tabelami-mermaid)
5. [Setup â€“ Å›rodowisko lokalne](#setup--Å›rodowisko-lokalne)
   - [Krok 1 â€“ instalacje zaleÅ¼noÅ›ci](#krok-1--instalacje-zaleÅ¼noÅ›ci)
   - [Krok 2 â€“ plik `.env`](#krok-2--plik-env)
   - [Krok 3 â€“ generowanie kluczy](#krok-3--generowanie-kluczy)
   - [Krok 4 â€“ uruchomienie Docker Compose](#krok-4--uruchomienie-docker-compose)
7. [DAG Airflow â€“ warehouse_daily](#dag-airflow--warehouse_daily)
8. [Warstwa ML â€“ trenowanie modeli i predykcje](#warstwa-ml--trenowanie-modeli-i-predykcje)
   - [Trenowanie i wybÃ³r najlepszego modelu](#trenowanie-i-wybÃ³r-najlepszego-modelu)
   - [Feature importance](#feature-importance)
   - [SHAP â€“ interpretowalnoÅ›Ä‡ modelu](#shap--interpretowalnoÅ›Ä‡-modelu)
   - [Predykcje nowych mieszkaÅ„](#predykcje-nowych-mieszkaÅ„)
9. [Artefakty ML â€“ co zostaje zapisane](#artefakty-ml--co-zostaje-zapisane)
10. [Wizualizacje projektu](#wizualizacje-projektu)
11. [Restart / zatrzymanie Å›rodowiska](#restart--zatrzymanie-Å›rodowiska)

---

## Architektura

**High-level:**

```text
Raw CSV
  â†“
Bronze (Pandas â†’ Parquet â†’ MinIO)
  â†“
Silver (SQL: typing, cleaning, validation)
  â†“
Gold (Feature engineering, KPI views, dane do ML)
  â†“
ML (trenowanie modeli, feature importance, SHAP, predykcje)

# ðŸ“ Struktura repozytorium
```
CaÅ‚oÅ›ciÄ… steruje DAG Airflow: warehouse_daily.

## Struktura repozytorium
```
mini-warehouse-ml/
â”œâ”€â”€ docker-compose.airflow.yml
â”œâ”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ airflow/                 # konfiguracja Airflow + docker-compose dla orkiestracji
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ warehouse_dag.py # gÅ‚Ã³wny DAG: bronze â†’ silver â†’ gold â†’ ML
â”‚   â”‚   â””â”€â”€ __pycache__
â”‚   â”‚	â”‚   â””â”€â”€ warehouse_dag.cpython-312.pyc
â”‚   â”œâ”€â”€ logs
â”‚   â”‚	â””â”€â”€ dag_processor_manager
â”‚   â”‚	â””â”€â”€ scheduler
â”‚   â”‚	â””â”€â”€ dag_id=warehouse_daily
â”‚   â”œâ”€â”€ home
â”‚
â”œâ”€â”€ etl/                     # ETL w Pythonie (bronze + integracja z MinIO)
â”‚   â”œâ”€â”€ extract.py           # CSV â†’ MinIO
â”‚   â”œâ”€â”€ transform.py         # pandas â†’ Parquet
â”‚   â””â”€â”€ load.py              # Parquet â†’ Postgres (bronze.housing_raw)
â”‚   â””â”€â”€ load_raw.py 		 # Surowy plik csv -> caÅ‚y proces "ETL" po stronie SQL
â”‚
â”œâ”€â”€ SQL/                     # SQL dla warstw silver / gold / walidacji
â”‚   â”œâ”€â”€ SQL_raw/			# SQL-owy ETL 
â”‚   â”‚   â””â”€â”€ 00_discovery/		# ekspolarcja danych raw
â”‚   â”‚	â”‚   â””â”€â”€ 010_schema_overview.sql
â”‚   â”‚	â”‚   â””â”€â”€ 020_null_heatmap.sql
â”‚   â”‚	â”‚   â””â”€â”€ 030_basix_statistics.sql
â”‚   â”‚   â””â”€â”€ 01_staging/			# czyszczenie i standaryzacja			
â”‚   â”‚	â”‚   â””â”€â”€ 110_handle_missing_values.sql
â”‚   â”‚	â”‚   â””â”€â”€ 120_cast_and_normalize.sql
â”‚   â”‚	â”‚   â””â”€â”€ 130_handle_logic.sql
â”‚   â”‚   â””â”€â”€ 02_gold/			# features, KPIs, outliers
â”‚   â”‚	â”‚   â””â”€â”€ 210_gold_feature.sql
â”‚   â”‚	â”‚   â””â”€â”€ 220_gold_valid.sql
â”‚   â”‚	â”‚   â””â”€â”€ 230_gold_invalid.sql
â”‚   â”‚	â”‚   â””â”€â”€ 240_price_city_daily.sql
â”‚   â”‚	â”‚   â””â”€â”€ 250_gold_outliers_iqr.sql
â”‚   â”‚	â”‚   â””â”€â”€ 260_gold_duplicates.sql
â”‚   â”‚	â”‚   â””â”€â”€ 270_gold_kpi.sql
â”‚   â”œâ”€â”€ SQL_after_etl/          # SQL po Python ETL
â”‚   â”‚   â””â”€â”€ 01_quality_checks.sql
â”‚   â”‚   â””â”€â”€ 02_standarize_types.sql
â”‚   â”‚   â””â”€â”€ 03_outliers_check.sql
â”‚   â”‚   â””â”€â”€ 04_buisness_logic_cleaning.sql
â”‚   â”‚   â””â”€â”€ 05_final_view.sql 
â”‚
â”œâ”€â”€ ml/                      # czÄ™Å›Ä‡ ML
â”‚   â”œâ”€â”€ ml_final.py          # trenowanie modeli + wybÃ³r najlepszego + log runÃ³w
â”‚   â”œâ”€â”€ feature_importance.py# wykres waÅ¼noÅ›ci cech
â”‚   â”œâ”€â”€ shap_explainer.py    # SHAP â€“ interpretacja modelu
â”‚   â””â”€â”€ predict_sample.py    # predykcje nowych mieszkaÅ„ + zapis do DB i Excela
â”‚   â””â”€â”€ __pycache__
â”‚   â””â”€â”€ artifacts
â”‚
â”œâ”€â”€ artifacts/               # wyjÅ›cia z ML (modele, metryki, wykresy, predykcje)
â”‚   â””â”€â”€ best_model_*.joblib
â”‚   â””â”€â”€ feature_importance.csv
â”‚   â””â”€â”€ feature_importance.png
â”‚   â””â”€â”€ model_metrics.csv
â”‚   â””â”€â”€ predictions_YYYY_MMDD_****.xlsx
â”‚   â””â”€â”€ shap_summary.png
â”‚   â””â”€â”€ shap_values.csv
â”‚
â”œâ”€â”€ data/                    # dane wejÅ›ciowe 
â”‚   â””â”€â”€ raw
â”‚      â””â”€â”€ housing_10k_sample.csv
â”‚      â””â”€â”€ housing_800k.csv
â”‚
â”œâ”€â”€ notebooks/               # praca eksploracyjna
â”‚   â””â”€â”€ explore_raw.ipynb
â”‚
â”œâ”€â”€ warehouse/               # dodatkowe materiaÅ‚y dot. ERD
â”‚   â””â”€â”€ erd.md
â”‚
â”œâ”€â”€ requirements.txt         # zaleÅ¼noÅ›ci Pythona (ML + lokalne skrypty)
â””â”€â”€ README.md
```
### Warstwy hurtowni danych

**Bronze â€” Raw Layer**

Warstwa **BRONZE** zawiera dane â€žas-isâ€, w formie najbardziej zbliÅ¼onej do ÅºrÃ³dÅ‚a, bez walidacji i bez typowania.
ZawartoÅ›Ä‡:
- bronze.housing_raw
Cechy:
- âœ” brak typÃ³w
- âœ” brak walidacji
- âœ” peÅ‚ne dane surowe

â¸»

**Silver â€” Clean Layer**

Warstwa **SILVER** zawiera dane oczyszczone, otagowane typami oraz gotowe do dalszego wzbogacania.
ZawartoÅ›Ä‡ (views):
- silver.housing_clean â€“ dane po walidacji, usuniÄ™te wartoÅ›ci bÅ‚Ä™dne
- silver.housing_typed â€“ ujednolicone typy, poprawione formaty dat/liczb
Cechy transformacji:
- usuwanie bÅ‚Ä™dnych rekordÃ³w
- konwersja typÃ³w
- normalizacja kolumn
- wstÄ™pne Å‚Ä…czenie danych

â¸»

**Gold â€” Feature Layer**

Warstwa **GOLD** jest uÅ¼ywana do analiz biznesowych i trenowania modeli ML.
Tabele:
- gold.housing_features â€“ gÅ‚Ã³wna tabela cech numerycznych i kategorycznych
- gold.outliers_iqr â€“ wykryte obserwacje odstajÄ…ce
- gold.price_city_daily â€“ dzienne statystyki cenowe per miasto
Widoki:
- gold.clean â€“ dane przefiltrowane, przygotowane do dalszej analizy
- gold.housing_valid â€“ ostateczny zbiÃ³r treningowo-walidacyjny dla modeli ML

â¸»

### ML â€” Model Predictions & Metadata

Schemat ML przechowuje wyniki predykcji oraz metadane treningÃ³w modeli.
- ml.housing_predictions
Predykcje wygenerowane przez najlepszy model:
- listing_id
- predicted_price_total
- scored_at
- model_path
- ml.model_runs
Log kaÅ¼dego treningu modelu:
- run_id
- model_name
- mae, rmse, r2
- train_rows, valid_rows
- scored_at
- pipeline_sha (hash pliku modelu)
---

### Podsumowanie warstw hurtowni danych

| Warstwa | Typ     | Obiekty                                                                 | Cel                                   |
|---------|---------|--------------------------------------------------------------------------|----------------------------------------|
| Bronze  | tabela  | `bronze.housing_raw`                                                     | dane surowe, ÅºrÃ³dÅ‚owe                  |
| Silver  | widoki  | `silver.housing_clean`, `silver.housing_typed`                           | czyszczenie, typowanie                 |
| Gold    | tabele  | `gold.housing_features`, `gold.outliers_iqr`, `gold.price_city_daily`    | cechy, agregacje, statystyki           |
| Gold    | widoki  | `gold.clean`, `gold.housing_valid`                                       | finalne dane do ML                     |
| ML      | tabele  | `ml.housing_predictions`, `ml.model_runs`                                | predykcje i metadane modeli            |


##  ERD â€“ zaleÅ¼noÅ›ci miÄ™dzy tabelami (Mermaid)

```mermaid
flowchart TD

  subgraph BRONZE ["Bronze â€“ Raw"]
    B1["bronze.housing_raw"]
  end

  subgraph SILVER ["Silver â€“ Clean"]
    S1["silver.housing_typed"]
    S2["silver.housing_clean"]
  end

  subgraph GOLD ["Gold â€“ Features & Views"]
    G1["gold.housing_features"]
    G2["gold.outliers_iqr"]
    G3["gold.price_city_daily"]
    GV1["gold.clean"]
    GV2["gold.housing_valid"]
  end

  subgraph ML ["ML â€“ Predictions & Runs"]
    M1["ml.housing_predictions"]
    M2["ml.model_runs"]
  end

  %% przepÅ‚yw danych
  B1 --> S1 --> S2 --> G1
  G1 --> GV1 --> GV2
  G1 --> G2
  G1 --> G3

  %% dane do ML
  GV2 --> M1
  GV2 --> M2
```

## Setup â€“ Å›rodowisko lokalne

**Wymagania**
	â€¢	Docker + Docker Compose
	â€¢	Python 3.10â€“3.12 (do lokalnego uruchamiania skryptÃ³w ML)
	â€¢	PostgreSQL lokalnie (jeÅ›li chcesz podglÄ…daÄ‡ dane poza kontenerem)

### Krok 1 â€“ instalacje zaleÅ¼noÅ›ci
**Instalacja zaleÅ¼noÅ›ci Python (dla lokalnego uruchamiania ML)**

W celu uruchomienia skryptÃ³w lokalnie, naleÅ¼y wykonaÄ‡ komende poniÅ¼ej:
```bash
python3 -m venv .venv
source .venv/bin/activate        # macOS/Linux
# lub
.venv\Scripts\activate           # Windows

pip install -r requirements.txt
```


### Krok 2 â€“ plik .env

W katalogu gÅ‚Ã³wnym projektu:
```bash
cp airflow/.env.example airflow/.env
nano airflow/.env
```
UzupeÅ‚nij wartoÅ›ci:

**Sekcja bezpieczeÅ„stwa:**
```bash
AIRFLOW__CORE__FERNET_KEY=<WSTAW_TUTAJ_FERNET_KEY>
AIRFLOW__WEBSERVER__SECRET_KEY=<WSTAW_TUTAJ_SECRET_KEY>
```

**Dane logowania do Airflow:**
```bash
_AIRFLOW_WWW_USER_CREATE=True
_AIRFLOW_WWW_USER_USERNAME=admin
_AIRFLOW_WWW_USER_PASSWORD=admin123
```

**PoÅ‚Ä…czenie do Postgresa z DAG-a:**
```bash
PG_HOST=host.docker.internal
PG_PORT=5432
PG_USER=postgres
PG_PASSWORD=postgres
PG_DB=warehouse
```

**MinIO:**
```bash
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=admin12345
S3_ENDPOINT=http://host.docker.internal:9000
```

### Krok 3 â€“ generowanie kluczy

**Fernet Key:**
```bash
python3 - <<'EOF'
from cryptography.fernet import Fernet
print(Fernet.generate_key().decode())
EOF
```

**Secret Key:**
```bash
openssl rand -hex 64
```

Wygenerowane wartoÅ›ci naleÅ¼y wkleiÄ‡ do airflow/.env.

### Krok 4 - uruchomienie Docker Compose 

```bash
docker compose -f docker-compose.airflow.yml up -d
```

Airflow UI bÄ™dzie dostÄ™pny pod adresem:
*http://localhost:8081*

Dane logowania:
```bash
Username: admin
Password: admin123
```

### Trouble shooting - problemy z logowaniem do Airflow

JeÅ›li domyÅ›lne logowanie nie dziaÅ‚a (np. po zmianie `_AIRFLOW_WWW_USER_*` albo pierwszym starcie kontenera), moÅ¼na zresetowaÄ‡ hasÅ‚o z poziomu Dockera:

1. WejÅ›cie do konternera Airflow:
```bash
docker compose -d docker-compose.airflow.yml exec airflow bash
```

2. Uruchamianie skryptu zmiany hasÅ‚a:
```bash
airflow users reset-password -u admin
```
NaleÅ¼y podac nowe hasÅ‚o, a nastÄ™pnie je powtÃ³rzyÄ‡.

3. WyjÅ›cie z kontera:
```bash
exit
```

## DAG Airflow â€“ warehouse_daily

Po wÅ‚Ä…czeniu DAG-a warehouse_daily w UI Airflow, pipeline wykona kolejno:
1.	**Extract** â€“ wrzucenie lokalnego CSV do MinIO
2.	**Transform** â€“ przetworzenie do Parquet (Pandas)
3.	**Load** â€“ import do Postgresa: bronze.housing_raw
4.	**Silver** â€“ handle_missing_values â€“ uzupeÅ‚nianie/obsÅ‚uga brakÃ³w
5.	**Silver** â€“ cast_and_normalize â€“ typowanie i normalizacja pÃ³l
6.	**Silver** â€“ logic checks â€“ reguÅ‚y biznesowe i jakoÅ›ciowe
7.	**Gold** â€“ features â€“ tworzenie cech (m.in. floor_ratio, season, area_sqm_bucket)
8.	**Gold** â€“ valid/invalid/duplicates â€“ widoki kontrolne
9.	**ML** â€“ train_models â€“ trenowanie modeli i zapis artefaktÃ³w
10.	**ML** â€“ feature_importance_ml â€“ generacja wykresu waÅ¼noÅ›ci cech
11.	**ML** â€“ shap_explainer_ml â€“ obliczenie SHAP i zapis wykresu
12.	**ML** â€“ Model_prediction_sample â€“ predykcja nowych mieszkaÅ„ + zapis do DB i Excela

## Warstwa ML â€“ trenowanie modeli i predykcje

### **Trenowanie i wybÃ³r najlepszego modelu**

Skrypt: ml/ml_final.py

Modele:
- RandomForestRegressor
- GradientBoostingRegressor
- XGBRegressor

Wykonywane kroki:
1.	Pobranie danych z gold.housing_valid
2.	PodziaÅ‚ na train / valid / test
3.	Zbudowanie preprocessora (ColumnTransformer â€“ num + cat)
4.	RandomizedSearchCV dla kaÅ¼dego modelu (MAE jako metryka)
5.	WybÃ³r najlepszego modelu (najniÅ¼sze MAE na valid)
6.	Zapis pipelineâ€™u do artifacts/best_model_<Model>.joblib
7.	Wyliczenie SHA256 pipelineâ€™u i zapis do ml.model_runs

### **Feature importance**

Skrypt: ml/feature_importance.py
- Å‚aduje best_model_*.joblib z katalogu artifacts/
- wyciÄ…ga feature_importances_
- zapisuje:
	- artifacts/feature_importance.csv
	- artifacts/feature_importance_top20.png â€“ wykres TOP 20 cech

### **SHAP â€“ interpretowalnoÅ›Ä‡ modelu**

Skrypt: ml/shap_explainer.py
- pobiera prÃ³bkÄ™ danych z gold.housing_valid
- uÅ¼ywa TreeExplainer (SHAP) dla najlepszego modelu
- zapisuje:
	- artifacts/shap_values.csv
	- artifacts/shap_summary.png â€“ wykres mean(|SHAP value|) dla top cech

### **Predykcje nowych mieszkaÅ„**

Skrypt: ml/predict_sample.py
1.	Pobiera N losowych rekordÃ³w z gold.housing_valid
2.	Odrzuca kolumnÄ™ price_total (target)
3.	Wylicza predykcje predicted_price_total przy uÅ¼yciu najlepszego modelu
4.	Zapisuje wyniki do:
	- Postgres: ml.housing_predictions
	- Excela: artifacts/predictions_<YYYYMMDD_HHMM>.xlsx

PrzykÅ‚adowe kolumny:
- listing_id
- predicted_price_total
- scored_at (UTC)
- model_path (np. best_model_RandomForest.joblib)

## Artefakty ML â€“ co zostaje zapisane

W katalogu artifacts/ powinno byÄ‡ widoczne m.in.:
**Modele i metryki:**
- best_model_<Model>.joblib
- model_metrics.csv
- feature_importance.csv
- feature_importance_top20.png
**SHAP:**
- shap_values.csv
- shap_summary.png
**Predykcje**:
- predictions_<YYYYMMDD_HHMM>.xlsx

## Wizualizacje projektu

### Airflow â€“ widok gÅ‚Ã³wny DAG-a
![Airflow main DAG](Screenshots/airflow_main_dag_overview.png)

### Airflow â€“ Graph View
![Airflow Graph View](Screenshots/airflow_dag_graph_overview.png)

### Airflow â€“ task trenowania modeli
![Train Models Task](Screenshots/airflow_train_models_task.png)

### MinIO â€“ Buckety
![MinIO buckets](Screenshots/minio_buckets_overview.png)

## Restart / zatrzymanie Å›rodowiska

Zatrzymanie kontenerÃ³w:
```bash
docker compose -d docker-compose.airflow.yml down
```

Uruchomienie ponowne:
```bash
docker compose -d docker-compose.airflow.yml up -d
```
---

## Autor

Projekt zostaÅ‚ w caÅ‚oÅ›ci zaprojektowany, zaimplementowany i udokumentowany przez:

**Mateusz Wykowski**  
Data Engineer & ML Enthusiast

Repozytorium stanowi element portfolio i pokazuje praktycznÄ… implementacjÄ™:
- end-to-end pipeline'u ETL w architekturze bronze â†’ silver â†’ gold,
- orkiestracji z uÅ¼yciem Apache Airflow,
- integracji z MinIO (S3),
- przetwarzania danych w Pythonie i SQL,
- peÅ‚nego cyklu ML: preprocessing, trenowanie, ewaluacja, SHAP, predykcje,
- oraz projektowych dobrych praktyk Data Engineering.

Kontakt: **MateusWykowski@gmail.com**

---
